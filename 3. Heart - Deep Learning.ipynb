{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease UCI Data Preprocessing -Neural Network\n",
    "Raw dataset was downloaded from Kaggle. The target is to build a machine learnign model to predict whether there is a chance of heart attack based on the different parameters. In this document I will use the Neural Network to learn the preprocessed dataset.\n",
    "## 1. Load the data\n",
    "This part I would like to import the data sets created when running the logistic regression. The inputs will be stored as float data type while the targets will be saved as interger data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A temporary variable npz is used for storing the assigning relevant inputs and targets\n",
    "npz = np.load('Heart_data_train.npz')\n",
    "train_inputs, train_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('Heart_data_validation.npz')\n",
    "validation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('Heart_data_test.npz')\n",
    "test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build the model\n",
    "In this part, I would use the tf.keras.layers.Dense to build the model. The hyperparameters to tune include the hidden layer size, the number of layers, the activation funcation and the batch size. After tuning the model, a 6 layer (5 hidden layer) neural network is chosen for the model, with batch size set to 5, and hidden layer size to be 20. The accuracy for training set is about 0.89, and the accuracy of the validation set is 0.84. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 181 samples, validate on 61 samples\n",
      "Epoch 1/100\n",
      "181/181 - 1s - loss: 0.6766 - accuracy: 0.6354 - val_loss: 0.6638 - val_accuracy: 0.7377\n",
      "Epoch 2/100\n",
      "181/181 - 0s - loss: 0.6500 - accuracy: 0.7017 - val_loss: 0.6267 - val_accuracy: 0.7705\n",
      "Epoch 3/100\n",
      "181/181 - 0s - loss: 0.6078 - accuracy: 0.7293 - val_loss: 0.5621 - val_accuracy: 0.7869\n",
      "Epoch 4/100\n",
      "181/181 - 0s - loss: 0.5437 - accuracy: 0.7790 - val_loss: 0.4769 - val_accuracy: 0.8197\n",
      "Epoch 5/100\n",
      "181/181 - 0s - loss: 0.4807 - accuracy: 0.8066 - val_loss: 0.4244 - val_accuracy: 0.8197\n",
      "Epoch 6/100\n",
      "181/181 - 0s - loss: 0.4314 - accuracy: 0.8343 - val_loss: 0.4149 - val_accuracy: 0.8197\n",
      "Epoch 7/100\n",
      "181/181 - 0s - loss: 0.3962 - accuracy: 0.8508 - val_loss: 0.4102 - val_accuracy: 0.8197\n",
      "Epoch 8/100\n",
      "181/181 - 0s - loss: 0.3772 - accuracy: 0.8729 - val_loss: 0.4090 - val_accuracy: 0.8197\n",
      "Epoch 9/100\n",
      "181/181 - 0s - loss: 0.3539 - accuracy: 0.8674 - val_loss: 0.4148 - val_accuracy: 0.8361\n",
      "Epoch 10/100\n",
      "181/181 - 0s - loss: 0.3373 - accuracy: 0.8840 - val_loss: 0.4119 - val_accuracy: 0.8361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c3e7192388>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the output size and the hidden layer size\n",
    "output_size = 1\n",
    "# Just choose the same size for all the hidden layers\n",
    "hidden_layer_size = 10\n",
    "    \n",
    "# define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 3rd hidden layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 4th hidden layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 5th hidden layer\n",
    "    # the final layer is no different, we just make sure to activate it with softmax\n",
    "    tf.keras.layers.Dense(output_size, activation='sigmoid') # output layer\n",
    "])\n",
    "\n",
    "\n",
    "### Choose the \"adam\" optimizer and the \"sparse_categorical_crossentropy\" loss function, use 'accuracy' as the metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "### Training\n",
    "# set the batch size\n",
    "batch_size = 5\n",
    "\n",
    "# set a maximum number of training epochs\n",
    "max_epochs = 100\n",
    "\n",
    "# set an early stopping mechanism, use patience=2\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "\n",
    "# fit the model\n",
    "model.fit(train_inputs, # train inputs\n",
    "          train_targets, # train targets\n",
    "          batch_size=batch_size, # batch size\n",
    "          epochs=max_epochs, # epochs(assuming early stopping doesn't kick in)\n",
    "          # callbacks are functions called by a task when a task is completed\n",
    "          # task here is to check if val_loss is increasing\n",
    "          callbacks=[early_stopping], # early stopping\n",
    "          validation_data=(validation_inputs, validation_targets), # validation data\n",
    "          verbose = 2 # making sure we get enough information about the training process\n",
    "          )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test the accuracy\n",
    "In this part the accuracy of the test set is calculated as 0.77, sklightly better than the logistic regression (0.75)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 193us/sample - loss: 0.4943 - accuracy: 0.7705\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-TF2.0]",
   "language": "python",
   "name": "conda-env-py3-TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
